{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Prise en main de GPT-2 et faire des tests pour interroger le modèle pré entraîné avec Jupyter Notebook et Tensorflow/Keras**\n",
        "\n",
        "(format: texte explicatif ; 17 Novembre 2023, rendu collectif) (Compétence 1 / Compétence 2)\n",
        "\n",
        "1.   Utilisation de **keras NLP**\n",
        "2.   Utilisation de **transformers**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aaNJ_7CKa50K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **I Utilisation de keras NLP**"
      ],
      "metadata": {
        "id": "LWD_uD1xs_6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installation de la bibliothèque Keras NLP**"
      ],
      "metadata": {
        "id": "XkUsXoAepbS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/keras-team/keras-nlp.git -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maf8vloVd2-Q",
        "outputId": "86301e5d-033a-4338-8ddf-7db81cb06f9f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importation des bibliothèques**"
      ],
      "metadata": {
        "id": "dH7Ucvktpo1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras_nlp\n",
        "import tensorflow as tf\n",
        "import keras_core as keras\n",
        "import time"
      ],
      "metadata": {
        "id": "55BLpVVhpvQ6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "# Le model gpt2_base_en correspond à une taille de 355M\n",
        "\n",
        "# Chargement du modèle GPT2\n",
        "\n",
        "preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
        "    \"gpt2_base_en\",\n",
        "    sequence_length=128,\n",
        ")\n",
        "gpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(\n",
        "    \"gpt2_base_en\", preprocessor=preprocessor\n",
        ")\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# Génére la réponse de gpt2 à travers le context (text) qu'on lui donne\n",
        "# La fonction prend en paramètre le context et un nombre correspondant à la longueur maximal généré par la réponse de GPT2\n",
        "output = gpt2_lm.generate(\"I would like to make money with\", max_length=50)\n",
        "print(\"\\nGPT-2 output:\")\n",
        "print(output)\n",
        "\n",
        "end = time.time()\n",
        "# calcul du temps d'éxécution du code\n",
        "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJrRLEczebrJ",
        "outputId": "0152ae35-6896-48c2-8955-0b2b6e79abc1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GPT-2 output:\n",
            "I would like to make money with your services. I am a freelance photographer. My work is based on personal experience. My goal is to help people in the field find their way through the world of photography. I'm also a freelance writer,\n",
            "TOTAL TIME ELAPSED: 68.05s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilisation de **transformers**"
      ],
      "metadata": {
        "id": "3yROV1Httvmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installation de la bibliothèque transformers**"
      ],
      "metadata": {
        "id": "5SAsoVBWuPfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "EQmXXlm_Tphu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b638392e-3138-44ca-e80f-09a6292e6914"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importation des bibliothèques**"
      ],
      "metadata": {
        "id": "42LVnLK_uYFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "0IBXNdbPuaeP"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On crée ici une pipeline qui va générer du texte en se basant sur le modèle ClassCat/gpt2-base-french\n",
        "# D'autres modèles peuvent êtres utilisé à contrario\n",
        "\n",
        "generator = pipeline('text-generation', model='ClassCat/gpt2-base-french')\n",
        "\n",
        "# on définit ici le contexte qu'on donnera à notre objet generator\n",
        "\n",
        "contexte = \"Il était une fois\"\n",
        "\n",
        "# On va générer la réponse de gpt2 en lui donnant en paramètres le contexte, la longueur maximal de chaque séquence générée et enfin le nombre de séquence généré\n",
        "\n",
        "response = generator(contexte, max_length=50, num_return_sequences=5)\n",
        "\n",
        "# On va ici parcourir les différences séquences retourée pour les afficher\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "  print(response[i]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCIHbh7vwIeG",
        "outputId": "6abe38cb-f805-43b4-e81e-cfa9a76dfdf0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Il était une fois dans l'ouest de la france au xvième siècle, une jeune famille pauvre, venue d'argentine pour échapper à la prostitution.\n",
            "Il était une fois quelques semaines en bretagne, un petit couple avec une petite nounou, avec une fille très curieuse, qui n'était pas particulièrement douée pour le dessin.\n",
            "Il était une fois une jeune fille qui devait avoir 15 ans.\n",
            "Il était une fois des mots du monde\n",
            "Il était une fois un ado, grand-mère, qui avait disparu pendant un voyage à venise, avec sa sœur de seize ans, au bord de la tamise. elle y mourut en tombant sous la neige.\n"
          ]
        }
      ]
    }
  ]
}