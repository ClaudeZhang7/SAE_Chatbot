{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C4hOJzui0GC",
        "outputId": "4f78a661-21f3-44e4-8ea3-ef5d21eb874c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9_nGmZplkwn",
        "outputId": "ef6c2d31-4e12-4ec9-a426-cbb58a10c5a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.2/465.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting clean-text\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting emoji<2.0.0,>=1.0.0 (from clean-text)\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy<7.0,>=6.0 (from clean-text)\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy<7.0,>=6.0->clean-text) (0.2.13)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171033 sha256=01ce2992b18917e97ff9012382d0e9b9ee4630c3b63fbbaf71f53bffe1ddd35b\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, ftfy, clean-text\n",
            "Successfully installed clean-text-0.6.0 emoji-1.7.0 ftfy-6.1.3\n",
            "Collecting unicode\n",
            "  Downloading unicode-2.9-py2.py3-none-any.whl (14 kB)\n",
            "Installing collected packages: unicode\n",
            "Successfully installed unicode-2.9\n"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade keras-nlp\n",
        "!pip install -q --upgrade keras  # Upgrade to Keras 3.\n",
        "!pip install clean-text\n",
        "!pip install unicode\n",
        "# !pip install keras==2.15.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Ik6OXLR8lkzt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # or \"tensorflow\" or \"torch\"\n",
        "\n",
        "import keras_nlp\n",
        "import keras\n",
        "\n",
        "# améliore la rapidité d'entrainement\n",
        "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3-rKDHxtFxS",
        "outputId": "23d1eaf1-d8a9-4ca8-f4e7-6d2a8c571c17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 44955 entries, 0 to 44954\n",
            "Data columns (total 1 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   OriginalTweet  44955 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 351.3+ KB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.concat([\n",
        "    pd.read_csv('/content/drive/MyDrive/Corona_NLP_test.csv')[['OriginalTweet']],\n",
        "    pd.read_csv('/content/drive/MyDrive/Corona_NLP_train.csv', encoding='iso-8859-1')[['OriginalTweet']]\n",
        "])\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxunnbfhFKqj"
      },
      "source": [
        "# **Pré-traitement**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3g_M1s_tGqj",
        "outputId": "6ffec04a-c594-481c-89e9-8a284560cade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "Tous les éléments sont uniques.\n"
          ]
        }
      ],
      "source": [
        "print(df['OriginalTweet'].isnull().sum())\n",
        "df.dropna(subset=['OriginalTweet'], how='any', inplace=True)\n",
        "df.reset_index(inplace=True, drop=True)\n",
        "\n",
        "unique_elements = not df['OriginalTweet'].duplicated().any()\n",
        "\n",
        "if unique_elements:\n",
        "    print(\"Tous les éléments sont uniques.\")\n",
        "else:\n",
        "    print(\"Certains éléments ne sont pas uniques.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "RbFJC39ytGsZ"
      },
      "outputs": [],
      "source": [
        "import cleantext\n",
        "import re\n",
        "# corrige les caractères unicode mal formaté\n",
        "# converti les caracteres non ASCII en leur équivalent exemple : é devient e\n",
        "\n",
        "df['OriginalTweet'] = df['OriginalTweet'].apply(lambda x: cleantext.clean(x,\n",
        "                                                                         fix_unicode=True,\n",
        "                                                                         to_ascii=True,\n",
        "                                                                         lower=True,\n",
        "                                                                         no_emails=True,\n",
        "                                                                         no_urls=True,\n",
        "                                                                         ))\n",
        "df['OriginalTweet'] = df['OriginalTweet'].str.replace('<url>', '')\n",
        "# traitement des character speciaux\n",
        "df['OriginalTweet'] = df['OriginalTweet'].apply(lambda x: re.sub(r'\\W', ' ', x))\n",
        "# on enleve les espaces en trop\n",
        "df['OriginalTweet'] = df['OriginalTweet'].str.replace(r'\\s{2,}', ' ', regex=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH-ODHW4tKvu",
        "outputId": "d8ed5a60-6dea-4635-ebfe-2fbb90e2f6de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 44955 entries, 0 to 44954\n",
            "Data columns (total 1 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   OriginalTweet  44955 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 351.3+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "Vb3n637UlqjX",
        "outputId": "5961eb48-f6da-4383-daaa-c2e9ab335054"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gpt2_causal_lm_preprocessor_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mPreprocessor: \"gpt2_causal_lm_preprocessor_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gpt2_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GPT2Tokenizer</span>)                     │                                              <span style=\"color: #00af00; text-decoration-color: #00af00\">50,257</span> │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gpt2_tokenizer (\u001b[38;5;33mGPT2Tokenizer\u001b[0m)                     │                                              \u001b[38;5;34m50,257\u001b[0m │\n",
              "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gpt2_causal_lm_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"gpt2_causal_lm_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gpt2_backbone (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GPT2Backbone</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">124,439,808</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50257</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">38,597,376</span> │ gpt2_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gpt2_backbone (\u001b[38;5;33mGPT2Backbone\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)         │     \u001b[38;5;34m124,439,808\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50257\u001b[0m)       │      \u001b[38;5;34m38,597,376\u001b[0m │ gpt2_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,439,808</span> (474.70 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m124,439,808\u001b[0m (474.70 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,439,808</span> (474.70 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m124,439,808\u001b[0m (474.70 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# initialisation pour l'utilisation du modèle GPT-2\n",
        "import pandas as pd\n",
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras_nlp.models import GPT2CausalLMPreprocessor, GPT2CausalLM\n",
        "\n",
        "preprocessor = GPT2CausalLMPreprocessor.from_preset(\n",
        "    \"gpt2_base_en\",\n",
        "    sequence_length=128,\n",
        ")\n",
        "\n",
        "gpt2_lm = GPT2CausalLM.from_preset(\n",
        "    \"gpt2_base_en\",\n",
        "    preprocessor=preprocessor\n",
        ")\n",
        "\n",
        "gpt2_lm.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtHNonkjlqlV",
        "outputId": "d7f64c11-b9a8-49a7-c08f-5031c3a6047d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                           OriginalTweet\n",
            "0      trending  new yorkers encounter empty supermar...\n",
            "1      when i couldn t find hand sanitizer at fred me...\n",
            "2      find out how you can protect yourself and love...\n",
            "3       panic buying hits  newyork city as anxious sh...\n",
            "4       toiletpaper  dunnypaper  coronavirus  coronav...\n",
            "...                                                  ...\n",
            "44950  airline pilots offering to stock supermarket s...\n",
            "44951  response to complaint not provided citing covi...\n",
            "44952  you know it s getting tough when  kameronwilds...\n",
            "44953  is it wrong that the smell of hand sanitizer i...\n",
            "44954   tartiicat well new used rift s are going for ...\n",
            "\n",
            "[44955 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d08uzWyPlqpJ",
        "outputId": "01c1aef8-738b-4e78-8db2-25010d98a462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['trending new yorkers encounter empty supermarket shelves pictured wegmans in brooklyn sold out online grocers foodkick maxdelivery as coronavirus fearing shoppers stock up ', 'when i couldn t find hand sanitizer at fred meyer i turned to amazon but 114 97 for a 2 pack of purell check out how coronavirus concerns are driving up prices ', 'find out how you can protect yourself and loved ones from coronavirus ', ' panic buying hits newyork city as anxious shoppers stock up on food medical supplies after healthcare worker in her 30s becomes bigapple 1st confirmed coronavirus patient or a bloomberg staged event qanon qanon2018 qanon2020 election2020 cdc ', ' toiletpaper dunnypaper coronavirus coronavirusaustralia coronavirusupdate covid_19 9news corvid19 7newsmelb dunnypapergate costco one week everyone buying baby milk powder the next everyone buying up toilet paper ', 'do you remember the last time you paid 2 99 a gallon for regular gas in los angeles prices at the pump are going down a look at how the coronavirus is impacting prices 4pm abc7 ', 'voting in the age of coronavirus hand sanitizer supertuesday ', ' drtedros we can t stop covid19 without protecting healthworkers prices of surgical masks have increased six fold n95 respirators have more than trebled gowns cost twice as much drtedros coronavirus', 'hi twitter i am a pharmacist i sell hand sanitizer for a living or i do when any exists like masks it is sold the fuck out everywhere should you be worried no use soap should you visit twenty pharmacies looking for the last bottle no pharmacies are full of sick people ', 'anyone been in a supermarket over the last few days went to do my normal shop last night is the sight that greeted me barmy btw what s so special about tinned tomatoes covid_19 dublin ']\n"
          ]
        }
      ],
      "source": [
        "text_df = list(df['OriginalTweet'].astype(str).values)\n",
        "print(text_df[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dawoMENVFphM",
        "outputId": "750c6453-ddff-4bef-efd5-ed1634843db2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m 344/1405\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:53\u001b[0m 560ms/step - accuracy: 0.2733 - loss: 1.5009"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "    num_epochs = 1\n",
        "    # Peut bien fonctionner lorsque vous vous attendez à ce que le taux d'apprentissage diminue rapidement au début de l'entraînement.\n",
        "    # Précision allant jusqu'à 35% avec un epoch à 1\n",
        "    learning_rate = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=5e-5,\n",
        "    decay_steps=len(text_df) * num_epochs,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True\n",
        "    )\n",
        "    # On utilisera le paramètre ci-dessous lorsque nos données ne seront pas traiter\n",
        "    # Permet un ajustement plus fin du taux d'apprentissage au fil du temps.\n",
        "    # Peut mieux s'adapter à des schémas d'apprentissage moins réguliers (les #, http etc les trucs inutiles / non logique de nos données).\n",
        "    # à utiliser avec un epoch au minimum de 3, 10 serait optimal\n",
        "\n",
        "    # initial_learning_rate peut être mis à 1e-3\n",
        "    # learning_rate = keras.optimizers.schedules.PolynomialDecay(\n",
        "    #     initial_learning_rate=5e-5,\n",
        "    #     decay_steps=len(text_df) * num_epochs,\n",
        "    #     end_learning_rate=0.0,\n",
        "    # )\n",
        "\n",
        "    # on va crée un callbacks dans le cas ou l'entrainement devient régréssant \n",
        "    # changer la valeur de patience selon l'epochs qu'on mettra  \n",
        "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    gpt2_lm.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss=loss,\n",
        "        weighted_metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    gpt2_lm.fit(\n",
        "        x=text_df,\n",
        "        epochs=num_epochs,\n",
        "        batch_size = 32,\n",
        "        callbacks=[early_stopping]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33qOkv9FlqrE",
        "outputId": "c20c5b24-5872-4b5f-d0dd-13b1c2f79744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "GPT-2 output:\n",
            "the coronavirus is a  pandemic  it s not just the consumer who is at risk  it s also the business community  the economy  consumer  economy is at stake  \n",
            "___________________________________________________________\n",
            "\n",
            "GPT-2 output:\n",
            "the coronavirus is a                            the                                     \n",
            "___________________________________________________________\n",
            "\n",
            "GPT-2 output:\n",
            "the coronavirus is a  global  pandemic  but what is the impact on  consumer spending and consumer confidence  the report reveals that                                 \n",
            "___________________________________________________________\n",
            "\n",
            "GPT-2 output:\n",
            "the coronavirus is a  socialdistancing virus  but how do you make it work when people walk in the grocery store     socialdistancing  socialdistancing  covid2019\n",
            "___________________________________________________________\n",
            "\n",
            "GPT-2 output:\n",
            "the coronavirus is a  socialdistancing   socialdistancing    the  coronavirus has created a  shortage of food   a scarcity of essential commodities and a  scarcity of  consumer            \n",
            "___________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# model gpt-2 de base\n",
        "for i in range(5):\n",
        "# Ne pas laisser d'espace avant le \" ça un impacte énorme !\n",
        "  seed_text = \"the coronavirus is a\"\n",
        "  # on peu rajouter le paramètre max_length si on veut\n",
        "  generated_text = gpt2_lm.generate(seed_text, max_length=100)\n",
        "  print(\"\\nGPT-2 output:\")\n",
        "  print(generated_text)\n",
        "  print('___________________________________________________________')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMGwwyCa6tnt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K50lvyaJ6tc6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
